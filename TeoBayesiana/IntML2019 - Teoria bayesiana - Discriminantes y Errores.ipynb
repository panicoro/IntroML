{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 [Georgina Flesia](georgina.flesia@unc.edu.ar)\n",
    "\n",
    "http://www.famaf.proed.unc.edu.ar/course/view.php?id=470\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IntML2019 - Teoria Bayesiana - Discriminantes y Errores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1. \n",
    "\n",
    "En el caso de dos categorias, la regla de decision de Bayes el error condicional\n",
    " esta dada por la ecuacion (7)\n",
    " $$P(error|x)=\\min [P (\\omega_1 | x), P (\\omega_2 | x)]$$ \n",
    " \n",
    " Incluso si las densidades a posteriori son continuas, esta forma de la condicional de errores casi siempre conduce a un integrando discontinuo en el calculo del error total en la ecuacion (5) $$P(error)=\\int P(error|x)p(x) dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (a) Demostrar que para densidades arbitrarias, podemos obtener una cota superior para el error total usando en la ecuacion anterior $$P(error|x)=2P (\\omega_1 | x) P (\\omega_2 | x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "Si suponemos que para un determinado $x$ se da que $P (\\omega_1 | x) \\geq P (\\omega_2 | x)$ luego por la regla anterior se cumple que $P(error|x)= P (\\omega_2 | x)$.\n",
    "\n",
    "Como sabemos $P (\\omega_1 | x) + P (\\omega_2 | x) = 1$, entonces se da que $P (\\omega_2 | x) = 1 - P (\\omega_1 | x)$\n",
    "\n",
    "Luego tenemos que $P (\\omega_1 | x) \\geq 1 - P (\\omega_1 | x) \\iff 2P (\\omega_1 | x) \\geq 1$. De lo que pobemos obtener:\n",
    "\n",
    "$$2P (\\omega_1 | x)P (\\omega_2 | x) \\geq P (\\omega_2 | x) = P (error | x)$$\n",
    "\n",
    "$$\\iff$$\n",
    "\n",
    "$$2P (\\omega_1 | x)P (\\omega_2 | x) p(x) \\geq  P (error | x) p(x)$$\n",
    "\n",
    "Si esto vale para todo $x$ entonces con las integrales también se cumple, por lo tanto:\n",
    "\n",
    "$$\\int 2P (\\omega_1 | x)P (\\omega_2 | x) p(x) dx \\geq  \\int P (error | x) p(x)dx = P(error) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (b) Demostrar que si en la ecuacion (5), utilizamos $P (error | x) =\\alpha P (\\omega_1 | x) P (\\omega_2 | x)$, con $\\alpha<2$, entonces no podemos garantizar que la integral de una cota superior para el error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "Se busca un contraejemplo, si tomamos $$P (\\omega_1 | x)= 0.7, P (\\omega_2 | x)=0.3,  \\alpha = 0.5 $$\n",
    "Entonces:\n",
    "\n",
    "$$ \\alpha P (\\omega_1 | x)P (\\omega_2 | x) = 0.5 \\times 0.7 \\times 0.3 = 0.105 < P (error | x) = 0.3 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (c) Analogamente, demostrar que podemos utilizar $$P (error | x) = P (\\omega_1 | x) P (\\omega_2 | x)$$ y obtener una cota inferior para el error total.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "Si suponemos que para un determinado $x$ se da que $P (\\omega_1 | x) \\geq P (\\omega_2 | x)$ luego por la regla anterior se cumple que $P(error|x)= P (\\omega_2 | x)$.\n",
    "\n",
    "Ademas sabemos que $$P(\\omega_1|x) \\leq 1$$\n",
    "\n",
    "$$\\iff$$\n",
    "\n",
    "$$P(\\omega_1|x)P(\\omega_2|x) \\leq P(\\omega_2|x) = P(error|x)$$\n",
    "\n",
    "$$\\iff$$\n",
    "\n",
    "$$P(\\omega_1|x)P(\\omega_2|x)p(x) \\leq P(error|x)p(x)$$\n",
    "\n",
    "Si esto vale para todo $x$ entonces con las integrales también se cumple, por lo tanto:\n",
    "\n",
    "$$\\int P (\\omega_1 | x)P (\\omega_2 | x) p(x) dx \\leq  \\int P (error | x) p(x)dx = P(error) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (d) Demostrar que si $P (error | x) =\\beta P (\\omega_1 | x) P (\\omega_2 | x)$ con $\\beta> 1$, entonces no podemos garantizar que la integral de una cota inferior para el error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "Se busca un contraejemplo, si tomamos $$P (\\omega_1 | x)= 0.6, P (\\omega_2 | x)=0.4,  \\beta = 2 $$\n",
    "Entonces:\n",
    "\n",
    "$$ \\beta P (\\omega_1 | x)P (\\omega_2 | x) = 2 \\times 0.6 \\times 0.4 = 0.48 > P (error | x) = 0.4 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2. \n",
    "\n",
    "Suponga que se tienen dos variables independiente con igual funcion densidad\n",
    "$$\n",
    "p(x|\\omega_i) = \\propto e^{(-|x-a_i|/b_i)}\n",
    "$$\n",
    "para $i=1,2$ and $0<b_i$.\n",
    "\n",
    "\n",
    "* (b) Calcule el radio de verosimilitud como función de los parametros.\n",
    "* (c) Graficar el radio $p(x|\\omega_1)/p(x|\\omega_2)$ para el caso $a_1=0$, $b_1=1$, $a_2=1$ y $b_2=2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (a)  Escriba una expresion analitica para cada densidad, es decir normalize cada funcion para parametros $a_i, b_i$ arbitrarios, $b_i$ positivo.\n",
    "\n",
    "**Respuesta**\n",
    "\n",
    "$$\\int{\\inf}{\\inf}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3. \n",
    "\n",
    "Si las distribuciones condicionales para las dos categorias en el problema unidimensional son distribuciones de Cauchy\n",
    "$$\n",
    "p(x|\\omega_i)=\\frac{1}{\\pi b}. \\frac{1}{1+(\\frac{x-a_i}{b})^2}\n",
    "$$\n",
    "\n",
    "* (a) Suponiendo que $P(\\omega_1) = P(\\omega_2)$, muestre que $P(\\omega_1 | x) = P (\\omega_2 | x)$ si $x =\\frac{a_1 + a_2}{2}$, es decir, el minimo para las cotas de la probabilidad de error en la decision es el punto medio entre los picos de las dos distribuciones, independientemente de la b.\n",
    "* (b)  Graficar $P(\\omega_1|x)$ para el caso de $a_1=3$, $a_2=5$ y $b = 1$.\n",
    "* (c)  ¿Como se comportan $P (\\omega_1 | x)$ y $P (\\omega_2 | x)$ cuando $x\\rightarrow\\infty$ y cuando $x\\rightarrow-\\infty$? Explicar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Ejercicio 4. \n",
    "\n",
    "Si las distribuciones condicionales para las dos categorias en el problema unidimensional son distribuciones de Cauchy, y asuma la igualdad entre las probabilidades a priori para las categorias.\n",
    "\n",
    "* (a) Demostrar que la probabilidad de error minimo esta dado por $$P (error) =\\displaystyle\\frac12-\\displaystyle\\frac{1}{\\pi}\\tan^{-1}\\left|\\displaystyle\\frac{a_2-a_1}{2b}\\right|$$\n",
    "* (b)  Graficar esto como una funcion de $\\displaystyle\\frac{a_2-a_1}{b}$.\n",
    "* (c) ¿Cual es el maximo de $P(error)$ y en que condiciones ocurre esto? Explicar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Ejercicio 5. \n",
    "\n",
    "Considere la siguiente regla de decisión para el problema de dos categorias unidimensional: Decido por $\\omega_1$ si $x>\\theta$; en otro caso decida por $\\omega_2$.\n",
    "\n",
    "* (a) Demuestre que la probabilidad de error para esta regla esta dada por \n",
    "$$P(error)=\\int P(error|x)p(x) dx= P(\\omega_1)\\int_{-\\infty}^\\theta p(x|\\omega_1) dx + P(\\omega_2)\\int^{\\infty}_\\theta p(x|\\omega_2) dx $$\n",
    "\n",
    "* (b) Derivando, demuestre que una condicion necesaria para minimizar el error es $$p(\\theta|\\omega_1)p(\\omega_1)=p(\\theta|\\omega_2)p(\\omega_2)$$\n",
    "\n",
    "* (c) Define esta ecuación un $\\theta$ unico?\n",
    "\n",
    "* (d)De un ejemplo de un valor de $\\theta$ en el que el error se maximice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 6. \n",
    "\n",
    "Supongamos que se sustituye la funcion de decision deterministica $\\alpha(x)$ por la regla aleatoria dada por la probabilidad $P(\\alpha_i|x)$ de tomar la decisi\\'on $\\alpha_i$ dado que se observo $x$.\n",
    "\n",
    "* (a) Mostrar que el riesgo resultante viene dado por\n",
    " $$R=\\displaystyle\\int\\left[\\displaystyle\\sum_{i=1}^aR(\\alpha_i|x)P(\\alpha_i|x)\\right]p(x)dx$$\n",
    "* (b) Ademas, demostrar que $R$ se minimiza para $P(\\alpha_i|x)=1$ para la accion $\\alpha_i$ asociada con el riesgo condicional minimo $R(\\alpha_i|x)$, lo que demuestra que no obtenemos ningun beneficio haciendo aleatoria la regla de decision.\n",
    "* (c) ¿Podemos beneficiarnos aleatorizando una regla suboptima? Explicar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
